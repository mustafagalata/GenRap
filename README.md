# ğŸ¤– GenRap: Stil BazlÄ± TÃ¼rkÃ§e Rap SÃ¶zÃ¼ Ãœretici
Bu, [PyTorch](https://pytorch.org/) ve [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) kÃ¼tÃ¼phaneleri kullanÄ±larak geliÅŸtirilmiÅŸ bir DoÄŸal Dil Ä°ÅŸleme (NLP) projesidir. Projenin amacÄ±, `ytu-ce-cosmos/turkish-gpt2` modelini, 240+ ÅŸarkÄ±dan oluÅŸan Ã¶zel etiketli bir TÃ¼rkÃ§e rap veri seti Ã¼zerinde "ince ayar" (fine-tuning) yaparak, verilen stil etiketlerine ([AGRESÄ°F], [FLEX], [FELSEFÄ°K] vb.) gÃ¶re orijinal rap ÅŸarkÄ± sÃ¶zleri Ã¼retebilen bir model oluÅŸturmaktÄ±r.

---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler ve KÃ¼tÃ¼phaneler
###  **Python 3.10+**

###  Derin Ã–ÄŸrenme & NLP:

- `PyTorch`: Modelin eÄŸitimi ve Ã§Ä±karÄ±mÄ± (inference) iÃ§in temel Ã§erÃ§eve.

- `Hugging Face Transformers`: Ã–n-eÄŸitimli modeli (`AutoModelForCausalLM`) ve sÃ¶zlÃ¼ÄŸÃ¼ (`AutoTokenizer`) yÃ¼klemek iÃ§in.

- `Hugging Face Datasets`: 'train.txt' dosyasÄ±nÄ± verimli bir ÅŸekilde iÅŸlemek iÃ§in.

### Veri Toplama:

- `Genius API`: ÅarkÄ± sÃ¶zÃ¼ verisinin kaynaÄŸÄ±.

- `lyricsgenius`: Genius API iÃ§in kullanÄ±lan Python sarmalayÄ±cÄ±sÄ± (wrapper).

### EÄŸitim OrtamÄ±:

- `Google Colab` (T4 GPU): Yetersiz lokal VRAM kÄ±sÄ±tlamasÄ±nÄ± aÅŸmak iÃ§in bulutta GPU ile eÄŸitim.

### AraÃ§lar:

- `Git & GitHub`: SÃ¼rÃ¼m kontrolÃ¼ ve portfÃ¶y sunumu.

- `python-dotenv`: API anahtarlarÄ±nÄ± gÃ¼venli bir ÅŸekilde saklamak iÃ§in.

- `venv`: Proje baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± izole etmek iÃ§in.

---

## ğŸ”„ Proje Ä°ÅŸ AkÄ±ÅŸÄ± (Pipeline)

Bu proje, bir makine Ã¶ÄŸrenimi projesinin 4 ana adÄ±mÄ±nÄ± takip eder:

### 1. Veri Toplama
* `lyricsgenius` kÃ¼tÃ¼phanesi kullanÄ±larak, belirlenen TÃ¼rk rap sanatÃ§Ä±larÄ±nÄ±n ÅŸarkÄ± sÃ¶zleri Genius API Ã¼zerinden Ã§ekildi.
* Her ÅŸarkÄ±, `raw_data/` klasÃ¶rÃ¼ altÄ±na `SanatÃ§Ä±-ÅarkÄ±AdÄ±.txt` formatÄ±nda ayrÄ± bir metin dosyasÄ± olarak kaydedildi.

### 2. Veri Ã–n Ä°ÅŸleme
* Projenin en kritik adÄ±mÄ±. 241 ÅŸarkÄ±nÄ±n tamamÄ±, `[AGRESÄ°F]`, `[MELANKOLÄ°K]`, `[FLEX]`, `[BATTLE]` gibi etiketler kullanÄ±larak **manuel olarak etiketlendi.**
* TÃ¼m ÅŸarkÄ± sÃ¶zlerini ve etiketlerini `[ETÄ°KET] [ETÄ°KET] <sÃ¶zler...>` formatÄ±nda birleÅŸtirdi.
* Modelin eÄŸitimde "bias" (Ã¶nyargÄ±) geliÅŸtirmemesi iÃ§in `random.shuffle()` kullanÄ±larak veri setinin tamamÄ± **karÄ±ÅŸtÄ±rÄ±ldÄ±**.

### 3. Model EÄŸitimi
* Lokal donanÄ±mÄ±n yetersizliÄŸi nedeniyle eÄŸitim sÃ¼reci **Google Colab** Ã¼zerinde, T4 GPU kullanÄ±larak gerÃ§ekleÅŸtirildi.
* `ytu-ce-cosmos/turkish-gpt2` modeli, `transformers` kÃ¼tÃ¼phanesinin `Trainer` API'si kullanÄ±larak `train.txt` Ã¼zerinde "ince ayar" (fine-tuning) yapÄ±ldÄ±.
* En iyi "kayÄ±p" (loss) deÄŸerini bulmak iÃ§in hiperparametre optimizasyonu (deney takibi) yapÄ±ldÄ±.
* EÄŸitim tamamlandÄ±ktan sonra, eÄŸitilmiÅŸ model dosyalarÄ± (`genrap-model` klasÃ¶rÃ¼) lokale indirildi.

### 4. SÃ¶z Ãœretimi
* EÄŸitilmiÅŸ olan `genrap-model` klasÃ¶rÃ¼ lokalden yÃ¼klendi.
* `model.generate()` fonksiyonu kullanÄ±larak, kullanÄ±cÄ± tarafÄ±ndan saÄŸlanan prompt'a (Ã¶rn: `[FELSEFÄ°K]`) gÃ¶re yeni sÃ¶zler Ã¼retildi.

---

## ğŸ“ˆ EÄŸitim ve Deney Raporu

En iyi modeli bulmak iÃ§in `num_train_epochs` (tur sayÄ±sÄ±) gibi hiperparametreler Ã¼zerinde deneyler yapÄ±lmÄ±ÅŸtÄ±r.

| Deney Kodu     | `num_train_epochs` (Tur) | `per_device_train_batch_size` (Paket) | EÄŸitim SÃ¼resi (YaklaÅŸÄ±k) | Son `Training Loss` DeÄŸeri                                                       |
|:---------------|:-------------------------|:--------------------------------------|:-------------------------|:---------------------------------------------------------------------------------|
| **v1 (Temel)** | 3                        | 2                                     | ~1 dakika  36 saniye     | **4.59** -> **4.24** -> **3.89** -> **3.60**                                     | 
| **v2**         | 8                        | 4                                     | ~2 dakika  56 saniye     | **4.43** -> **3.81** -> **3.41** -> **3.14** -> **2.85** -> **2.64**             |
| **v3 (Final)** | 10                       | 4                                     | ~3 dakika  44 saniye     | **4.43** -> **3.81** -> **3.39** -> **3.10** -> **2.75** -> **2.50** -> **2.36** |


---
## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma
**Not:** Bu proje, `.gitignore` ile korunduÄŸu iÃ§in eÄŸitilmiÅŸ model dosyalarÄ±nÄ± (`genrap-model`), etiketleri veya ham veriyi iÃ§ermez. Projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in kendi modelinizi bu script'leri kullanarak eÄŸitmeniz gerekmektedir.

**1. Kurulum:**

```bash
# Projeyi klonlayÄ±n
git clone https://github.com/mustafagalata/GenRap.git
cd GenRap

# Sanal ortamÄ± kurun ve aktive edin
python -m venv venv
venv\Scripts\activate

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt

# API anahtarÄ±nÄ±zÄ± ayarlayÄ±n
# Proje ana dizininde .env dosyasÄ± oluÅŸturun ve iÃ§ine ÅŸunu ekleyin:
# GENIUS_ACCESS_TOKEN="CLIENT_ACCESS_TOKENINIZI_BURAYA_YAZIN"
```

**2. Proje AkÄ±ÅŸÄ±nÄ± Ã‡alÄ±ÅŸtÄ±rma:**
```bash
# 1. Ham veriyi toplayÄ±n
python data_collection.py

# 2. Veri iÅŸleme ÅŸablonunu (data_processing_template.py)
#    doldurun ve 'data_processing.py' olarak Ã§alÄ±ÅŸtÄ±rÄ±n.

python data_processing.py

# 3. Modelinizi Google Colab'de 'model_training.py' script'i ile eÄŸitin
#    ve eÄŸitilmiÅŸ 'genrap-model' klasÃ¶rÃ¼nÃ¼ bu dizine indirin.

# 4. EÄŸitilmiÅŸ modelinizle sÃ¶z Ã¼retin!
python generate_lyrics.py
```
---

## âš ï¸ SÄ±nÄ±rlamalar ve Veri UyarÄ±sÄ± (Limitations and Data Warning)

Bu model, Ã§ok Ã§eÅŸitli sanatÃ§Ä±lardan toplanan gerÃ§ek dÃ¼nya rap ÅŸarkÄ± sÃ¶zleri Ã¼zerinde eÄŸitilmiÅŸtir. Rap mÃ¼zik tÃ¼rÃ¼, doÄŸasÄ± gereÄŸi toplumsal eleÅŸtiri, protesto, argo dil (`profanity`) ve zaman zaman saldÄ±rgan veya tartÄ±ÅŸmalÄ± temalar iÃ§erebilmektedir.

**"Veri Neyse, Model Odur" (Data In, Model Out) ilkesi gereÄŸi:**

* Modelin Ã¼rettiÄŸi ÅŸarkÄ± sÃ¶zleri, orijinal veri setindeki bu argo ve tartÄ±ÅŸmalÄ± ifadeleri **taklit edebilir** ve yansÄ±tabilir.
* Ãœretilen metinler, geliÅŸtiricinin kiÅŸisel gÃ¶rÃ¼ÅŸlerini **yansÄ±tmaz** ve toplumsal normlara uygun olmayabilir.

Bu modelin Ã§Ä±ktÄ±larÄ±, bu riskler gÃ¶z Ã¶nÃ¼nde bulundurularak ve sorumlu bir ÅŸekilde kullanÄ±lmalÄ±dÄ±r.